# -*- coding: utf-8 -*-
"""Copy of student_performance_prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SUUT8DCmU7nkd0tARd3Dn68kCAmc1doZ
"""

# Code to read csv file into colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.ensemble import AdaBoostClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import log_loss,roc_auc_score,accuracy_score,confusion_matrix
import seaborn as sns 
from sklearn.ensemble import RandomForestClassifier

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

downloaded = drive.CreateFile({'id':'1VEpYTm-arzymvZkareL33UhLDToHE1YE'})
downloaded.GetContentFile('features.csv')

train1 = pd.read_csv('features.csv')
train1.head()

le=preprocessing.LabelEncoder()
le.fit(train1['school'])

le.classes_

le.fit(train1['sex'])
train1['sex']=le.transform(train1['sex'])

le.fit(train1['subject'])
train1['subject']=le.transform(train1['subject'])

le.fit(train1['address'])
train1['address']=le.transform(train1['address'])

le.fit(train1['famsize'])
train1['famsize']=le.transform(train1['famsize'])

le.fit(train1['Pstatus'])
train1['Pstatus']=le.transform(train1['Pstatus'])

le.fit(train1['Mjob'])
train1['Mjob']=le.transform(train1['Mjob'])

le.fit(train1['Fjob'])
train1['Fjob']=le.transform(train1['Fjob'])

le.fit(train1['reason'])
train1['reason']=le.transform(train1['reason'])

le.fit(train1['guardian'])
train1['guardian']=le.transform(train1['guardian'])

le.fit(train1['schoolsup'])
train1['schoolsup']=le.transform(train1['schoolsup'])

le.fit(train1['famsup'])
train1['famsup']=le.transform(train1['famsup'])

le.fit(train1['paid'])
train1['paid']=le.transform(train1['paid'])

le.fit(train1['activities'])
train1['activities']=le.transform(train1['activities'])

le.fit(train1['nursery'])
train1['nursery']=le.transform(train1['nursery'])

le.fit(train1['higher'])
train1['higher']=le.transform(train1['higher'])

le.fit(train1['internet'])
train1['internet']=le.transform(train1['internet'])

le.fit(train1['romantic'])
train1['romantic']=le.transform(train1['romantic'])

# train1 = pd.get_dummies(train1)

train1.head(10)

train1['FinalGrade'] = 'na'
train1.loc[(train1.G3 >= 18) & (train1.G3 <= 20), 'FinalGrade'] = 'Excellent'
train1.loc[(train1.G3 >= 15) & (train1.G3 <= 17), 'FinalGrade'] = 'Good' 
train1.loc[(train1.G3 >= 11) & (train1.G3 <= 14), 'FinalGrade'] = 'Satisfactory' 
train1.loc[(train1.G3 >= 6) & (train1.G3 <= 10), 'FinalGrade'] = 'Poor' 
train1.loc[(train1.G3 >= 0) & (train1.G3 <= 5), 'FinalGrade'] = 'Failure' 
train1.head(5)

le.fit(train1['FinalGrade'])
train1['FinalGrade']=le.transform(train1['FinalGrade'])
le.fit(train1['Regularity'])
train1['Regularity']=le.transform(train1['Regularity'])
le.fit(train1['Grade1'])
train1['Grade1']=le.transform(train1['Grade1'])
le.fit(train1['Grade2'])
train1['Grade2']=le.transform(train1['Grade2'])
train1.head()

y=train1.FinalGrade
train1 = train1.drop(labels=['G3','FinalGrade'],axis=1)
train1.head()

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)
X_train = pd.get_dummies(X_train)
X_test = pd.get_dummies(X_test)
len(list(X_train))

lr = LogisticRegression(multi_class='multinomial', solver='newton-cg',fit_intercept=True)
ks=[]
for i in range(1,61):
    sk = SelectKBest(chi2, k=i)
    x_new = sk.fit_transform(X_train,y_train)
    x_new_test=sk.fit_transform(X_test,y_test)
    l = lr.fit(x_new, y_train)
    ll = l.score(x_new_test, y_test)
    ks.append(ll)  
    
ks = pd.Series(ks)
ks = ks.reindex(list(range(1,61)))
ks

plt.figure(figsize=(10,5))
ks.plot.line()
plt.title('Feature Selction', fontsize=20)
plt.xlabel('Number of Feature Used', fontsize=16)
plt.ylabel('Prediction Accuracy', fontsize=16)

ks.where(ks==ks.max()).dropna()

sk = SelectKBest(chi2, k=8)
x_new = sk.fit_transform(X_train,y_train)
x_new_test=sk.fit_transform(X_test,y_test)
lr = lr.fit(x_new, y_train)
print("Logistic Regression Model Score" , ":" , lr.score(x_new, y_train) , "," ,
      "Cross Validation Score" ,":" , lr.score(x_new_test, y_test))

train1.shape

train1.dropna().shape



alcohol_index = pd.crosstab(index=train1.Grade2, columns=train1.Dalc)
workday_alcohol_index = alcohol_index.apply(perc).reindex(index)
workday_alcohol_index.plot.bar(fontsize=16, figsize=(14,8))
plt.title('Grade By workday alcohol Consumption', fontsize=20)
plt.ylabel('Percentage of Students ', fontsize=16)
plt.xlabel('Final Grade', fontsize=16)
plt.savefig('Grade_workday_alchol.png', bbox_inches='tight')
plt.show()

perc = (lambda col: col/col.sum())
index = ['Failure','Poor','Satisfactory','Good','Excellent']
relationship_index = pd.crosstab(index=train1.Grade2, columns=train1.age)
romantic_index = relationship_index.apply(perc).reindex(index)
romantic_index.plot.bar(fontsize=16, figsize=(14,8))
plt.title('Grade By age ', fontsize=20)
plt.ylabel('Percentage of Students', fontsize=16)
plt.xlabel('Final Grade', fontsize=16)
plt.savefig('Grade_Age.png', bbox_inches='tight')
plt.show()

goout_index = pd.crosstab(index=train1.Grade2, columns=train1.goout)
Overall_goout_index = goout_index.apply(perc).reindex(index)
Overall_goout_index.plot.bar(colormap='jet',fontsize=16, figsize=(14,8))
plt.title('Grade By Going Out frequency', fontsize=20)
plt.ylabel('Percentage of Students ', fontsize=16)
plt.xlabel('Final Grade', fontsize=16)
plt.savefig('Grade_going_out.png', bbox_inches='tight')
plt.show()

train1.head()
train1['Regularity'] = 'na'
train1.loc[(train1.absences >= 0) & (train1.absences <= 9), 'Regularity'] = 'Always Regular'
train1.loc[(train1.absences >= 10) & (train1.absences <= 29), 'Regularity'] = 'Mostly Regular' 
train1.loc[(train1.absences >= 30) & (train1.absences <= 49), 'Regularity'] = 'Regular' 
train1.loc[(train1.absences >= 50) & (train1.absences <= 79), 'Regularity'] = 'Irregular' 
train1.loc[(train1.absences >= 80)& (train1.absences <= 93), 'Regularity'] = 'Highly Irregular'
train1.head()

index = ['Failure','Poor','Satisfactory','Good','Excellent']
absences = pd.crosstab(index=train1.Grade2, columns=train1.Regularity)
absences = perc(absences)
absences.plot.bar(fontsize=16, figsize=(14,8))
plt.title('Grade by students regularity', fontsize=20)
plt.ylabel('Percentage of Students', fontsize=16)
plt.xlabel('Final Grade', fontsize=16)
plt.show()
plt.savefig('Grade_regularity.png', bbox_inches='tight')

index = ['Failure','Poor','Satisfactory','Good','Excellent']
studytime_index = pd.crosstab(index=train1.Grade2, columns=train1.studytime)
studytime_index = studytime_index.apply(perc).reindex(index)
studytime_index.plot.bar(fontsize=16, figsize=(14,8))
plt.title('Grade By Study Time', fontsize=20)
plt.ylabel('Percentage of Students', fontsize=16)
plt.xlabel('Final Grade', fontsize=16)
plt.savefig('Grade_study_time.png', bbox_inches='tight')

plt.show()

index = ['Failure','Poor','Satisfactory','Good','Excellent']
status_index = pd.crosstab(index=train1.Grade2, columns=train1.failures)
status_index = status_index.apply(perc).reindex(index)
status_index.plot.bar(fontsize=16, figsize=(14,8))
plt.title('Grade By failures', fontsize=20)
plt.ylabel('Percentage of Students', fontsize=16)
plt.xlabel('Final Grade', fontsize=16)
plt.savefig('Grade_Failure_status.png', bbox_inches='tight')

plt.show()

index = ['Failure','Poor','Satisfactory','Good','Excellent']
status_index = pd.crosstab(index=train1.Grade2, columns=train1.freetime)
status_index = status_index.apply(perc).reindex(index)
status_index.plot.bar(fontsize=16, figsize=(14,8))
plt.title('Grade By freetime', fontsize=20)
plt.ylabel('Percentage of Students', fontsize=16)
plt.xlabel('Final Grade', fontsize=16)
plt.savefig('Grade_freetime_status.png', bbox_inches='tight')

plt.show()

labels = list(range(0,21))
cm=confusion_matrix(y_val,y_pred)
a4_dims = (11.7, 8.27)
fig, ax = plt.subplots(figsize=a4_dims)
ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);